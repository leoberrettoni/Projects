{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/leo/Desktop/Day3/dataset_day3/train_set.csv', skiprows=[1977])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELEX_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Citations</th>\n",
       "      <th>01-07</th>\n",
       "      <th>01-10</th>\n",
       "      <th>01-20</th>\n",
       "      <th>01-30</th>\n",
       "      <th>01-40</th>\n",
       "      <th>01-50</th>\n",
       "      <th>01-60</th>\n",
       "      <th>...</th>\n",
       "      <th>17-30</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>19-10</th>\n",
       "      <th>19-20</th>\n",
       "      <th>19-30</th>\n",
       "      <th>19-40</th>\n",
       "      <th>19-50</th>\n",
       "      <th>20-10</th>\n",
       "      <th>20-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32012D0012(01)</td>\n",
       "      <td>14.7.2012 EN Official Journal of the European ...</td>\n",
       "      <td>['OJL341,22.12.2011,p.65', 'OJL331,14.12.2011,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52018DP0022</td>\n",
       "      <td>21.12.2018 EN Official Journal of the European...</td>\n",
       "      <td>['OJL353,31.12.2008,p.1', 'OJL208,2.8.2016,p.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32020D1214(02)</td>\n",
       "      <td>14.12.2020 EN Official Journal of the European...</td>\n",
       "      <td>['OJC315I,23.9.2020,p.5', 'OJL141,27.5.2011,p.1']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32010D1007(01)</td>\n",
       "      <td>7.10.2010 EN Official Journal of the European ...</td>\n",
       "      <td>['OJL8,12.1.2001,p.1', 'OJL196,24.7.2008,p.1',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32019D1742</td>\n",
       "      <td>21.10.2019 EN Official Journal of the European...</td>\n",
       "      <td>['OJL128,9.5.2013,p.1', 'OJL96,31.3.2004,p.1',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>32014D0309</td>\n",
       "      <td>29.5.2014 EN Official Journal of the European ...</td>\n",
       "      <td>['OJL147,1.6.2013,p.14']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>32015D0887</td>\n",
       "      <td>10.6.2015 EN Official Journal of the European ...</td>\n",
       "      <td>['OJL140,5.6.2009,p.16', 'OJL350,28.12.1998,p....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>32016D0804(01)</td>\n",
       "      <td>4.8.2016 EN Official Journal of the European U...</td>\n",
       "      <td>['OJC26,30.1.1999,p.23', 'OJL353,28.12.2013,p....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>32022D0024</td>\n",
       "      <td>10.1.2022 EN Official Journal of the European ...</td>\n",
       "      <td>['OJL262,15.10.2019,p.58']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>32014D0262</td>\n",
       "      <td>9.5.2014 EN Official Journal of the European U...</td>\n",
       "      <td>['OJL160,18.6.2011,p.21', 'OJL176,10.7.1999,p....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1976 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CELEX_ID                                               Text  \\\n",
       "0     32012D0012(01)  14.7.2012 EN Official Journal of the European ...   \n",
       "1        52018DP0022  21.12.2018 EN Official Journal of the European...   \n",
       "2     32020D1214(02)  14.12.2020 EN Official Journal of the European...   \n",
       "3     32010D1007(01)  7.10.2010 EN Official Journal of the European ...   \n",
       "4         32019D1742  21.10.2019 EN Official Journal of the European...   \n",
       "...              ...                                                ...   \n",
       "1971      32014D0309  29.5.2014 EN Official Journal of the European ...   \n",
       "1972      32015D0887  10.6.2015 EN Official Journal of the European ...   \n",
       "1973  32016D0804(01)  4.8.2016 EN Official Journal of the European U...   \n",
       "1974      32022D0024  10.1.2022 EN Official Journal of the European ...   \n",
       "1975      32014D0262  9.5.2014 EN Official Journal of the European U...   \n",
       "\n",
       "                                              Citations  01-07  01-10  01-20  \\\n",
       "0     ['OJL341,22.12.2011,p.65', 'OJL331,14.12.2011,...      0      0      0   \n",
       "1     ['OJL353,31.12.2008,p.1', 'OJL208,2.8.2016,p.1...      0      0      0   \n",
       "2     ['OJC315I,23.9.2020,p.5', 'OJL141,27.5.2011,p.1']      0      0      0   \n",
       "3     ['OJL8,12.1.2001,p.1', 'OJL196,24.7.2008,p.1',...      0      0      0   \n",
       "4     ['OJL128,9.5.2013,p.1', 'OJL96,31.3.2004,p.1',...      0      0      0   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "1971                           ['OJL147,1.6.2013,p.14']      0      0      0   \n",
       "1972  ['OJL140,5.6.2009,p.16', 'OJL350,28.12.1998,p....      0      0      0   \n",
       "1973  ['OJC26,30.1.1999,p.23', 'OJL353,28.12.2013,p....      0      0      0   \n",
       "1974                         ['OJL262,15.10.2019,p.58']      0      0      0   \n",
       "1975  ['OJL160,18.6.2011,p.21', 'OJL176,10.7.1999,p....      0      0      0   \n",
       "\n",
       "      01-30  01-40  01-50  01-60  ...  17-30  18  19  19-10  19-20  19-30  \\\n",
       "0         0      0      0      0  ...      0   0   0      0      0      0   \n",
       "1         0      1      0      0  ...      0   0   0      0      0      0   \n",
       "2         0      1      0      0  ...      0   0   0      0      0      0   \n",
       "3         0      0      0      0  ...      0   0   0      0      0      0   \n",
       "4         0      0      0      0  ...      0   0   0      0      0      0   \n",
       "...     ...    ...    ...    ...  ...    ...  ..  ..    ...    ...    ...   \n",
       "1971      0      0      0      0  ...      0   1   0      0      0      0   \n",
       "1972      0      0      0      0  ...      0   0   0      0      0      0   \n",
       "1973      0      0      1      0  ...      0   0   0      0      0      0   \n",
       "1974      0      0      0      0  ...      0   1   0      0      0      0   \n",
       "1975      0      0      0      0  ...      0   0   0      1      0      0   \n",
       "\n",
       "      19-40  19-50  20-10  20-20  \n",
       "0         0      0      0      0  \n",
       "1         0      0      0      0  \n",
       "2         0      0      0      0  \n",
       "3         0      0      0      0  \n",
       "4         0      0      0      0  \n",
       "...     ...    ...    ...    ...  \n",
       "1971      0      0      0      0  \n",
       "1972      0      0      0      0  \n",
       "1973      0      0      0      0  \n",
       "1974      0      0      0      0  \n",
       "1975      0      0      0      0  \n",
       "\n",
       "[1976 rows x 96 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all zeros: ['01-30', '02', '02-07', '03', '03-40', '05-07', '05-10', '07-07', '08-10', '08-20', '09', '10-07', '10-40', '11-20', '12-07', '12-20', '14', '14-07', '14-10', '14-20', '19-50', '20-10']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have read your data into a DataFrame named df\n",
    "columns_with_all_zeros = df.columns[(df == 0).all()].tolist()\n",
    "print(f\"Columns with all zeros: {columns_with_all_zeros}\")\n",
    "print(len(columns_with_all_zeros))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop([col for col in columns_with_all_zeros], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all zeros: ['01-30', '02', '02-07', '03', '03-40', '05-07', '05-10', '07-07', '08-10', '08-20', '09', '10-07', '10-40', '11-20', '12-07', '12-20', '14', '14-07', '14-10', '14-20', '19-50', '20-10']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have read your data into a DataFrame named df\n",
    "columns_with_all_zeros = df.columns[(df == 0).all()].tolist()\n",
    "print(f\"Columns with all zeros: {columns_with_all_zeros}\")\n",
    "print(len(columns_with_all_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all zeros: []\n"
     ]
    }
   ],
   "source": [
    "rows_with_all_zeros = df.index[(df.iloc[:, 3:] == 0).all(axis=1)].tolist()\n",
    "print(f\"Rows with all zeros: {rows_with_all_zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['Text']\n",
    "y=df.iloc[:,3:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize text\n",
    "X_train = X_train.apply(simple_preprocess)\n",
    "X_test = X_test.apply(simple_preprocess)\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Word2Vec parameters\n",
    "vector_size = 50  # Change based on your computational capabilities\n",
    "window = 5\n",
    "min_count = 2\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=X_train, vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
    "\n",
    "# Save model for future use if needed\n",
    "model.save(\"word2vec_model.model\")\n",
    "import numpy as np\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "X_train = X_train.apply(lambda x: document_vector(model, x))\n",
    "X_test = X_test.apply(lambda x: document_vector(model, x))\n",
    "X_train = pd.DataFrame(X_train.tolist())\n",
    "X_test = pd.DataFrame(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.tolist())\n",
    "X_test = pd.DataFrame(X_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-03 19:02:14,333] A new study created in memory with name: no-name-b4f34c09-a309-432e-bd7d-193e873eafb8\n",
      "[I 2023-09-03 19:02:20,529] Trial 0 finished with value: 0.9939618125441979 and parameters: {'learning_rate': 0.05152861604222512, 'max_depth': 9, 'subsample': 0.8727740055471181, 'colsample_bytree': 0.9477541193945005, 'n_estimators': 70, 'alpha': 0.407103253731825}. Best is trial 0 with value: 0.9939618125441979.\n",
      "[I 2023-09-03 19:02:25,930] Trial 1 finished with value: 0.9941794048849473 and parameters: {'learning_rate': 0.31635726770935263, 'max_depth': 9, 'subsample': 0.9035096122109791, 'colsample_bytree': 0.7074227345693926, 'n_estimators': 90, 'alpha': 0.8269840597985357}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:02:34,146] Trial 2 finished with value: 0.9937986182886356 and parameters: {'learning_rate': 0.028931012668274154, 'max_depth': 6, 'subsample': 0.6263356408856002, 'colsample_bytree': 0.923889352591276, 'n_estimators': 110, 'alpha': 0.3724962448989012}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:02:39,599] Trial 3 finished with value: 0.9941794048849473 and parameters: {'learning_rate': 0.2920078555794239, 'max_depth': 7, 'subsample': 0.8085594157997282, 'colsample_bytree': 0.9429915879064601, 'n_estimators': 90, 'alpha': 0.2605036987872196}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:02:47,011] Trial 4 finished with value: 0.9938167509836981 and parameters: {'learning_rate': 0.02881646068483057, 'max_depth': 11, 'subsample': 0.7144688793358371, 'colsample_bytree': 0.899612370112393, 'n_estimators': 100, 'alpha': 0.947111047055907}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:02:56,451] Trial 5 finished with value: 0.9937623528985107 and parameters: {'learning_rate': 0.011382775999845383, 'max_depth': 11, 'subsample': 0.8280979651614779, 'colsample_bytree': 0.911684836622156, 'n_estimators': 120, 'alpha': 0.03720351194510885}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:00,503] Trial 6 finished with value: 0.9933090355219492 and parameters: {'learning_rate': 0.017538117876339358, 'max_depth': 10, 'subsample': 0.8854271069193942, 'colsample_bytree': 0.5355183984072509, 'n_estimators': 60, 'alpha': 0.5985149680667274}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:04,282] Trial 7 finished with value: 0.9933996989972614 and parameters: {'learning_rate': 0.0199283245025224, 'max_depth': 11, 'subsample': 0.5955474969128032, 'colsample_bytree': 0.764952213636916, 'n_estimators': 50, 'alpha': 0.07904916669074169}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:13,884] Trial 8 finished with value: 0.9937986182886356 and parameters: {'learning_rate': 0.02035016960218322, 'max_depth': 4, 'subsample': 0.7034822933499871, 'colsample_bytree': 0.6662560798774896, 'n_estimators': 140, 'alpha': 0.034276317679064916}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:17,603] Trial 9 finished with value: 0.9937986182886355 and parameters: {'learning_rate': 0.1779266444708719, 'max_depth': 4, 'subsample': 0.5620802044277724, 'colsample_bytree': 0.7978100918218198, 'n_estimators': 50, 'alpha': 0.009023252524895442}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:19,429] Trial 10 finished with value: 0.9935628932528237 and parameters: {'learning_rate': 0.3530631222900613, 'max_depth': 2, 'subsample': 0.9825550354763004, 'colsample_bytree': 0.640616158932464, 'n_estimators': 20, 'alpha': 0.8594240850504344}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:25,538] Trial 11 finished with value: 0.9941068741046974 and parameters: {'learning_rate': 0.48079736095766634, 'max_depth': 8, 'subsample': 0.8014841371803734, 'colsample_bytree': 0.9851539210083096, 'n_estimators': 90, 'alpha': 0.6833104402807003}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:33,004] Trial 12 finished with value: 0.9940524760195103 and parameters: {'learning_rate': 0.16403015140535188, 'max_depth': 7, 'subsample': 0.960587656074593, 'colsample_bytree': 0.830169026610857, 'n_estimators': 80, 'alpha': 0.9908449515785118}. Best is trial 1 with value: 0.9941794048849473.\n",
      "[I 2023-09-03 19:03:43,002] Trial 13 finished with value: 0.9942882010553221 and parameters: {'learning_rate': 0.2130442844130582, 'max_depth': 6, 'subsample': 0.7608397021616722, 'colsample_bytree': 0.8405344187200605, 'n_estimators': 130, 'alpha': 0.2563056754367961}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:03:56,951] Trial 14 finished with value: 0.9941794048849475 and parameters: {'learning_rate': 0.12644424458754103, 'max_depth': 5, 'subsample': 0.7492689369832854, 'colsample_bytree': 0.7265529170240723, 'n_estimators': 150, 'alpha': 0.7249895728177717}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:04:16,507] Trial 15 finished with value: 0.9942700683602597 and parameters: {'learning_rate': 0.10970035100686101, 'max_depth': 5, 'subsample': 0.7389908734392067, 'colsample_bytree': 0.8425910478189358, 'n_estimators': 150, 'alpha': 0.5883501908117047}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:04:33,351] Trial 16 finished with value: 0.9939618125441977 and parameters: {'learning_rate': 0.08163977866674366, 'max_depth': 2, 'subsample': 0.6679123476853595, 'colsample_bytree': 0.8486064339242595, 'n_estimators': 130, 'alpha': 0.517774075349954}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:04:53,377] Trial 17 finished with value: 0.994161272189885 and parameters: {'learning_rate': 0.0836544970900916, 'max_depth': 5, 'subsample': 0.7662730241931515, 'colsample_bytree': 0.839376067418546, 'n_estimators': 150, 'alpha': 0.19692619854819027}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:05:07,291] Trial 18 finished with value: 0.9942338029701348 and parameters: {'learning_rate': 0.19675922438267415, 'max_depth': 3, 'subsample': 0.5107877520377709, 'colsample_bytree': 0.8730719090873738, 'n_estimators': 130, 'alpha': 0.47407072129124883}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:05:21,814] Trial 19 finished with value: 0.994233802970135 and parameters: {'learning_rate': 0.1149812545120305, 'max_depth': 6, 'subsample': 0.671720065694388, 'colsample_bytree': 0.790482338657451, 'n_estimators': 120, 'alpha': 0.3092843870326569}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:05:40,532] Trial 20 finished with value: 0.9941794048849475 and parameters: {'learning_rate': 0.059591259845181585, 'max_depth': 4, 'subsample': 0.7436805873816216, 'colsample_bytree': 0.8705060019448234, 'n_estimators': 150, 'alpha': 0.1737020517401724}. Best is trial 13 with value: 0.9942882010553221.\n",
      "[I 2023-09-03 19:05:53,431] Trial 21 finished with value: 0.9943063337503847 and parameters: {'learning_rate': 0.1138129787029512, 'max_depth': 6, 'subsample': 0.674938363673261, 'colsample_bytree': 0.7937596947703542, 'n_estimators': 120, 'alpha': 0.32025332084228847}. Best is trial 21 with value: 0.9943063337503847.\n",
      "[I 2023-09-03 19:06:06,355] Trial 22 finished with value: 0.9942519356651974 and parameters: {'learning_rate': 0.12093871177958335, 'max_depth': 6, 'subsample': 0.6623921254612982, 'colsample_bytree': 0.7870039373674721, 'n_estimators': 130, 'alpha': 0.4750666021486866}. Best is trial 21 with value: 0.9943063337503847.\n",
      "[I 2023-09-03 19:06:16,766] Trial 23 finished with value: 0.9941794048849475 and parameters: {'learning_rate': 0.24551760279915819, 'max_depth': 7, 'subsample': 0.708816301808616, 'colsample_bytree': 0.8201612084423807, 'n_estimators': 110, 'alpha': 0.3255126770902274}. Best is trial 21 with value: 0.9943063337503847.\n",
      "[I 2023-09-03 19:06:30,482] Trial 24 finished with value: 0.9941975375800098 and parameters: {'learning_rate': 0.21965903355363783, 'max_depth': 5, 'subsample': 0.7756356576412492, 'colsample_bytree': 0.8758902397559509, 'n_estimators': 140, 'alpha': 0.4163310682698297}. Best is trial 21 with value: 0.9943063337503847.\n",
      "[I 2023-09-03 19:06:43,106] Trial 25 finished with value: 0.9943788645306345 and parameters: {'learning_rate': 0.13914141515945083, 'max_depth': 8, 'subsample': 0.7308712256651814, 'colsample_bytree': 0.7420569500730272, 'n_estimators': 110, 'alpha': 0.24015986137750162}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:06:54,614] Trial 26 finished with value: 0.9941431394948222 and parameters: {'learning_rate': 0.16142958944912014, 'max_depth': 8, 'subsample': 0.6306609853769434, 'colsample_bytree': 0.7499512290721994, 'n_estimators': 110, 'alpha': 0.25852329922393014}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:07:06,625] Trial 27 finished with value: 0.9941068741046976 and parameters: {'learning_rate': 0.154714772765273, 'max_depth': 8, 'subsample': 0.7019713017239141, 'colsample_bytree': 0.7586082106241159, 'n_estimators': 120, 'alpha': 0.1472908505210972}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:07:16,417] Trial 28 finished with value: 0.9942338029701348 and parameters: {'learning_rate': 0.2595015100799275, 'max_depth': 9, 'subsample': 0.7751139567752724, 'colsample_bytree': 0.802123345346361, 'n_estimators': 100, 'alpha': 0.2306204798948201}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:07:27,261] Trial 29 finished with value: 0.9939074144590104 and parameters: {'learning_rate': 0.06729848453059428, 'max_depth': 7, 'subsample': 0.835194959532684, 'colsample_bytree': 0.9896617620510042, 'n_estimators': 70, 'alpha': 0.14152899891198145}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:07:39,390] Trial 30 finished with value: 0.994161272189885 and parameters: {'learning_rate': 0.050839745631689685, 'max_depth': 12, 'subsample': 0.7303497241468109, 'colsample_bytree': 0.7031843568721252, 'n_estimators': 100, 'alpha': 0.33288797220154265}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:07:53,589] Trial 31 finished with value: 0.9941794048849473 and parameters: {'learning_rate': 0.09731343267871514, 'max_depth': 6, 'subsample': 0.7393957807061552, 'colsample_bytree': 0.8347599577850175, 'n_estimators': 130, 'alpha': 0.4243692257729561}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:08:07,725] Trial 32 finished with value: 0.9941612721898848 and parameters: {'learning_rate': 0.12506379474213533, 'max_depth': 5, 'subsample': 0.789538105661927, 'colsample_bytree': 0.8102306918235416, 'n_estimators': 140, 'alpha': 0.27436863923981464}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:08:21,967] Trial 33 finished with value: 0.994233802970135 and parameters: {'learning_rate': 0.09569804805912353, 'max_depth': 9, 'subsample': 0.6877269574966106, 'colsample_bytree': 0.8905513346570986, 'n_estimators': 120, 'alpha': 0.3692451992014598}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:08:36,780] Trial 34 finished with value: 0.9943425991405096 and parameters: {'learning_rate': 0.2081218137776569, 'max_depth': 6, 'subsample': 0.7392453628985668, 'colsample_bytree': 0.9362963913528146, 'n_estimators': 140, 'alpha': 0.21074877167409928}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:08:49,413] Trial 35 finished with value: 0.9941068741046978 and parameters: {'learning_rate': 0.20104212239074112, 'max_depth': 6, 'subsample': 0.8532557972883993, 'colsample_bytree': 0.9396630132277595, 'n_estimators': 110, 'alpha': 0.22621858616856377}. Best is trial 25 with value: 0.9943788645306345.\n",
      "[I 2023-09-03 19:09:02,298] Trial 36 finished with value: 0.9943969972256969 and parameters: {'learning_rate': 0.33560019135711755, 'max_depth': 8, 'subsample': 0.788185452429299, 'colsample_bytree': 0.9272282368083788, 'n_estimators': 140, 'alpha': 0.11471062831126916}. Best is trial 36 with value: 0.9943969972256969.\n",
      "[I 2023-09-03 19:09:15,104] Trial 37 finished with value: 0.9944332626158218 and parameters: {'learning_rate': 0.3114531171030667, 'max_depth': 8, 'subsample': 0.8077837121802327, 'colsample_bytree': 0.9663826432278892, 'n_estimators': 140, 'alpha': 0.09838739090076648}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:09:28,044] Trial 38 finished with value: 0.9942882010553221 and parameters: {'learning_rate': 0.3368796253229847, 'max_depth': 10, 'subsample': 0.8231681079559136, 'colsample_bytree': 0.9576580915134337, 'n_estimators': 140, 'alpha': 0.09892229228451054}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:09:40,522] Trial 39 finished with value: 0.9942882010553222 and parameters: {'learning_rate': 0.44296218824852956, 'max_depth': 8, 'subsample': 0.7966450879065368, 'colsample_bytree': 0.9122111910183075, 'n_estimators': 140, 'alpha': 0.09645910884753131}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:09:51,680] Trial 40 finished with value: 0.9943607318355719 and parameters: {'learning_rate': 0.2729785585970027, 'max_depth': 10, 'subsample': 0.8694462772916838, 'colsample_bytree': 0.9682707075932707, 'n_estimators': 100, 'alpha': 0.05269273768929036}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:02,317] Trial 41 finished with value: 0.9943063337503847 and parameters: {'learning_rate': 0.30095955027744226, 'max_depth': 10, 'subsample': 0.8590388234627908, 'colsample_bytree': 0.9556915468115879, 'n_estimators': 100, 'alpha': 0.06459827937425511}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:11,330] Trial 42 finished with value: 0.9942882010553221 and parameters: {'learning_rate': 0.374144114546197, 'max_depth': 9, 'subsample': 0.897362134856897, 'colsample_bytree': 0.9331772516519373, 'n_estimators': 80, 'alpha': 0.00039997021606796856}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:23,000] Trial 43 finished with value: 0.9942156702750723 and parameters: {'learning_rate': 0.28258146984118243, 'max_depth': 8, 'subsample': 0.8297940256776577, 'colsample_bytree': 0.9670987694061565, 'n_estimators': 110, 'alpha': 0.1221936866804001}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:32,416] Trial 44 finished with value: 0.9941975375800097 and parameters: {'learning_rate': 0.39534798374048885, 'max_depth': 10, 'subsample': 0.8009187771460121, 'colsample_bytree': 0.9958269587753557, 'n_estimators': 90, 'alpha': 0.06954568577665857}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:45,986] Trial 45 finished with value: 0.9943425991405096 and parameters: {'learning_rate': 0.30042685724899326, 'max_depth': 9, 'subsample': 0.8833487214403951, 'colsample_bytree': 0.9249179748514712, 'n_estimators': 140, 'alpha': 0.15745276720160076}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:51,247] Trial 46 finished with value: 0.9940706087145726 and parameters: {'learning_rate': 0.24308384039441594, 'max_depth': 12, 'subsample': 0.9148525841537134, 'colsample_bytree': 0.9051990547496942, 'n_estimators': 30, 'alpha': 0.04448254678995909}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:10:58,846] Trial 47 finished with value: 0.9942882010553221 and parameters: {'learning_rate': 0.4508441573201761, 'max_depth': 7, 'subsample': 0.8118646797932779, 'colsample_bytree': 0.9735479252090173, 'n_estimators': 70, 'alpha': 0.1949909710491921}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:11:12,471] Trial 48 finished with value: 0.9943425991405096 and parameters: {'learning_rate': 0.3360464168760566, 'max_depth': 11, 'subsample': 0.7237385986611246, 'colsample_bytree': 0.9431889708070489, 'n_estimators': 150, 'alpha': 0.102245396702796}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:11:23,607] Trial 49 finished with value: 0.9942519356651973 and parameters: {'learning_rate': 0.26672385149084826, 'max_depth': 7, 'subsample': 0.7623561263051968, 'colsample_bytree': 0.9998072673508691, 'n_estimators': 100, 'alpha': 0.03291166069886292}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:11:37,201] Trial 50 finished with value: 0.9941612721898848 and parameters: {'learning_rate': 0.18183961260391965, 'max_depth': 8, 'subsample': 0.7805937690207391, 'colsample_bytree': 0.9678469926777875, 'n_estimators': 120, 'alpha': 0.19766657366485474}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:11:50,895] Trial 51 finished with value: 0.9943425991405094 and parameters: {'learning_rate': 0.32144733007485043, 'max_depth': 9, 'subsample': 0.8777596014788677, 'colsample_bytree': 0.9248536253033371, 'n_estimators': 140, 'alpha': 0.14742620894377376}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:12:03,967] Trial 52 finished with value: 0.9944151299207594 and parameters: {'learning_rate': 0.29352676410020806, 'max_depth': 9, 'subsample': 0.8478369194297467, 'colsample_bytree': 0.939577209224159, 'n_estimators': 130, 'alpha': 0.17000620049531404}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:12:16,006] Trial 53 finished with value: 0.9942700683602597 and parameters: {'learning_rate': 0.41088913779257213, 'max_depth': 10, 'subsample': 0.8127589336193751, 'colsample_bytree': 0.9482935443524046, 'n_estimators': 130, 'alpha': 0.10254241855906865}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:12:29,121] Trial 54 finished with value: 0.9942519356651973 and parameters: {'learning_rate': 0.23082800139069137, 'max_depth': 9, 'subsample': 0.8420066682430718, 'colsample_bytree': 0.9143146475215512, 'n_estimators': 130, 'alpha': 0.07026704120852265}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:12:42,531] Trial 55 finished with value: 0.9942700683602599 and parameters: {'learning_rate': 0.39114951161265626, 'max_depth': 8, 'subsample': 0.7533796568389649, 'colsample_bytree': 0.9772444449302281, 'n_estimators': 120, 'alpha': 0.17560415940199364}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:12:59,154] Trial 56 finished with value: 0.9943063337503845 and parameters: {'learning_rate': 0.4996312628215574, 'max_depth': 7, 'subsample': 0.8563910956433193, 'colsample_bytree': 0.8945530468261347, 'n_estimators': 150, 'alpha': 0.13543106171831276}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:13:18,084] Trial 57 finished with value: 0.9942156702750723 and parameters: {'learning_rate': 0.27564355899476867, 'max_depth': 11, 'subsample': 0.7879857651215425, 'colsample_bytree': 0.9522298281781244, 'n_estimators': 130, 'alpha': 0.025820024507751255}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:13:37,206] Trial 58 finished with value: 0.9943607318355722 and parameters: {'learning_rate': 0.2023880811593025, 'max_depth': 10, 'subsample': 0.8186718246000594, 'colsample_bytree': 0.9772794119331145, 'n_estimators': 150, 'alpha': 0.11917800356402743}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:13:55,990] Trial 59 finished with value: 0.9942338029701348 and parameters: {'learning_rate': 0.14826696436418876, 'max_depth': 10, 'subsample': 0.8198979625248434, 'colsample_bytree': 0.9883642958578496, 'n_estimators': 150, 'alpha': 0.04999314279797176}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:14:06,455] Trial 60 finished with value: 0.9943244664454471 and parameters: {'learning_rate': 0.23769599317559545, 'max_depth': 11, 'subsample': 0.8690843060537253, 'colsample_bytree': 0.973960582657343, 'n_estimators': 80, 'alpha': 0.1195333876695526}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:14:22,031] Trial 61 finished with value: 0.9942882010553221 and parameters: {'learning_rate': 0.19296423638868596, 'max_depth': 9, 'subsample': 0.7577043561432745, 'colsample_bytree': 0.9329023472619572, 'n_estimators': 140, 'alpha': 0.221907262754023}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:14:39,430] Trial 62 finished with value: 0.9943244664454471 and parameters: {'learning_rate': 0.2158132732696435, 'max_depth': 8, 'subsample': 0.7985132540879782, 'colsample_bytree': 0.9604647663093664, 'n_estimators': 150, 'alpha': 0.17565915905907936}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:14:53,962] Trial 63 finished with value: 0.994233802970135 and parameters: {'learning_rate': 0.34458641607210383, 'max_depth': 10, 'subsample': 0.8421729921698137, 'colsample_bytree': 0.9809367780734706, 'n_estimators': 140, 'alpha': 0.08361524627438832}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:15:07,269] Trial 64 finished with value: 0.9942700683602599 and parameters: {'learning_rate': 0.2775241910569267, 'max_depth': 9, 'subsample': 0.8184553870810577, 'colsample_bytree': 0.9207118753886315, 'n_estimators': 130, 'alpha': 0.017567468926046895}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:15:24,283] Trial 65 finished with value: 0.9943063337503847 and parameters: {'learning_rate': 0.17643571293308896, 'max_depth': 8, 'subsample': 0.7759270923873913, 'colsample_bytree': 0.9463363903089442, 'n_estimators': 150, 'alpha': 0.12219410607750705}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:15:37,533] Trial 66 finished with value: 0.9941975375800098 and parameters: {'learning_rate': 0.22520677856692364, 'max_depth': 7, 'subsample': 0.7672846262722872, 'colsample_bytree': 0.9997050569366581, 'n_estimators': 110, 'alpha': 0.2653011943361382}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:15:48,300] Trial 67 finished with value: 0.9942700683602597 and parameters: {'learning_rate': 0.20118642779743623, 'max_depth': 9, 'subsample': 0.7167040740964091, 'colsample_bytree': 0.8896610022274654, 'n_estimators': 90, 'alpha': 0.1585729548411682}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:16:01,385] Trial 68 finished with value: 0.9939799452392605 and parameters: {'learning_rate': 0.3088621972059267, 'max_depth': 10, 'subsample': 0.7386641195992214, 'colsample_bytree': 0.8549525094548903, 'n_estimators': 140, 'alpha': 0.21569424910104945}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:16:15,491] Trial 69 finished with value: 0.9943063337503848 and parameters: {'learning_rate': 0.13722018890542284, 'max_depth': 7, 'subsample': 0.8069060672174097, 'colsample_bytree': 0.9057281725144306, 'n_estimators': 120, 'alpha': 0.29128063592934333}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:16:30,401] Trial 70 finished with value: 0.9943425991405096 and parameters: {'learning_rate': 0.1703818192076038, 'max_depth': 8, 'subsample': 0.7491889537640438, 'colsample_bytree': 0.937642333536825, 'n_estimators': 140, 'alpha': 0.06402106624777812}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:16:45,422] Trial 71 finished with value: 0.9943788645306344 and parameters: {'learning_rate': 0.2927630695638492, 'max_depth': 9, 'subsample': 0.8810032426292093, 'colsample_bytree': 0.9240205247075255, 'n_estimators': 150, 'alpha': 0.24670426955089228}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:17:02,112] Trial 72 finished with value: 0.9943969972256972 and parameters: {'learning_rate': 0.26051691084087736, 'max_depth': 9, 'subsample': 0.8383628160143538, 'colsample_bytree': 0.9569445458509932, 'n_estimators': 150, 'alpha': 0.23441813473203563}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:17:18,806] Trial 73 finished with value: 0.9942700683602597 and parameters: {'learning_rate': 0.2528433446430303, 'max_depth': 9, 'subsample': 0.8365038661750773, 'colsample_bytree': 0.9615364786762245, 'n_estimators': 150, 'alpha': 0.1765616276710637}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:17:34,256] Trial 74 finished with value: 0.9943063337503848 and parameters: {'learning_rate': 0.355418597534292, 'max_depth': 10, 'subsample': 0.8943888489026315, 'colsample_bytree': 0.9795840810644304, 'n_estimators': 150, 'alpha': 0.26931064545510386}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:17:49,472] Trial 75 finished with value: 0.9942700683602596 and parameters: {'learning_rate': 0.29833062153565415, 'max_depth': 8, 'subsample': 0.9116209103587355, 'colsample_bytree': 0.9545277193169608, 'n_estimators': 150, 'alpha': 0.2415460015096208}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:18:03,437] Trial 76 finished with value: 0.9943244664454471 and parameters: {'learning_rate': 0.24514575830931457, 'max_depth': 9, 'subsample': 0.8712833041233353, 'colsample_bytree': 0.9114547656036356, 'n_estimators': 130, 'alpha': 0.2451547046939535}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:18:18,009] Trial 77 finished with value: 0.9943607318355722 and parameters: {'learning_rate': 0.3276056986385475, 'max_depth': 10, 'subsample': 0.8496452292517187, 'colsample_bytree': 0.925442460114712, 'n_estimators': 150, 'alpha': 0.29560724043866865}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:18:32,119] Trial 78 finished with value: 0.9943788645306345 and parameters: {'learning_rate': 0.37433787633390064, 'max_depth': 9, 'subsample': 0.8420190045427142, 'colsample_bytree': 0.929795420591126, 'n_estimators': 150, 'alpha': 0.29706434187528113}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:18:45,018] Trial 79 finished with value: 0.9943425991405094 and parameters: {'learning_rate': 0.4382882245381795, 'max_depth': 8, 'subsample': 0.8364113658104083, 'colsample_bytree': 0.8896449076992737, 'n_estimators': 140, 'alpha': 0.3389547215773893}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:18:58,590] Trial 80 finished with value: 0.9943244664454471 and parameters: {'learning_rate': 0.3715132618373992, 'max_depth': 9, 'subsample': 0.8204119070628385, 'colsample_bytree': 0.8735027088877608, 'n_estimators': 150, 'alpha': 0.23829393847345004}. Best is trial 37 with value: 0.9944332626158218.\n",
      "[I 2023-09-03 19:19:14,120] Trial 81 finished with value: 0.9944513953108843 and parameters: {'learning_rate': 0.3093742069137974, 'max_depth': 9, 'subsample': 0.8492629160126342, 'colsample_bytree': 0.9265396146576996, 'n_estimators': 150, 'alpha': 0.29594042034438417}. Best is trial 81 with value: 0.9944513953108843.\n",
      "[I 2023-09-03 19:19:28,235] Trial 82 finished with value: 0.9944332626158221 and parameters: {'learning_rate': 0.3619395442229559, 'max_depth': 9, 'subsample': 0.8616383859665121, 'colsample_bytree': 0.937134682475628, 'n_estimators': 140, 'alpha': 0.29236825007368333}. Best is trial 81 with value: 0.9944513953108843.\n",
      "[I 2023-09-03 19:19:42,785] Trial 83 finished with value: 0.9943425991405097 and parameters: {'learning_rate': 0.4065704599638051, 'max_depth': 9, 'subsample': 0.8619661679383468, 'colsample_bytree': 0.9289989508388113, 'n_estimators': 140, 'alpha': 0.3023056861621375}. Best is trial 81 with value: 0.9944513953108843.\n",
      "[W 2023-09-03 19:19:48,581] Trial 84 failed with parameters: {'learning_rate': 0.35639598342491535, 'max_depth': 8, 'subsample': 0.8847132600193007, 'colsample_bytree': 0.9419823936705397, 'n_estimators': 140, 'alpha': 0.2800297012875331} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/fn/cfz1v8ln76s58pxjvj3vk_hh0000gn/T/ipykernel_34795/133380351.py\", line 19, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py\", line 450, in fit\n",
      "    super().fit(X, Y, sample_weight, **fit_params)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py\", line 216, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1051, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1915, in update\n",
      "    self._validate_dmatrix_features(dtrain)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 2739, in _validate_dmatrix_features\n",
      "    if self.feature_names is None:\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1868, in feature_names\n",
      "    return self._get_feature_info(\"feature_name\")\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1830, in _get_feature_info\n",
      "    feature_info = from_cstr_to_pystr(sarr, length)\n",
      "  File \"/Users/leo/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 102, in from_cstr_to_pystr\n",
      "    res.append(str(cast(bytes, data[i]).decode('ascii')))\n",
      "KeyboardInterrupt\n",
      "[W 2023-09-03 19:19:48,594] Trial 84 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptuna\u001b[39;00m\n\u001b[1;32m     32\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m best_params_xgb \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[1;32m     36\u001b[0m best_score_xgb \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      8\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.5\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     10\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m12\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m model \u001b[39m=\u001b[39m MultiOutputClassifier(xgb\u001b[39m.\u001b[39mXGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams))\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Predict the labels for test data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m predicted_labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    425\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \n\u001b[1;32m    427\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y, sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[1;32m    452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    217\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    220\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     47\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1915\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[1;32m   1914\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid training matrix: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(dtrain)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1915\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39mhandle))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:2739\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2736\u001b[0m ft \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfeature_types\n\u001b[1;32m   2737\u001b[0m \u001b[39m# Be consistent with versions before 1.7, \"validate\" actually modifies the\u001b[39;00m\n\u001b[1;32m   2738\u001b[0m \u001b[39m# booster.\u001b[39;00m\n\u001b[0;32m-> 2739\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2740\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39m=\u001b[39m fn\n\u001b[1;32m   2741\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1868\u001b[0m, in \u001b[0;36mBooster.feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1863\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_names\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[FeatureNames]:\n\u001b[1;32m   1864\u001b[0m     \u001b[39m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m \u001b[39m    assignment.\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \n\u001b[1;32m   1867\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1868\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_feature_info(\u001b[39m\"\u001b[39;49m\u001b[39mfeature_name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1830\u001b[0m, in \u001b[0;36mBooster._get_feature_info\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m   1824\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m _check_call(\n\u001b[1;32m   1826\u001b[0m     _LIB\u001b[39m.\u001b[39mXGBoosterGetStrFeatureInfo(\n\u001b[1;32m   1827\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, c_str(field), ctypes\u001b[39m.\u001b[39mbyref(length), ctypes\u001b[39m.\u001b[39mbyref(sarr),\n\u001b[1;32m   1828\u001b[0m     )\n\u001b[1;32m   1829\u001b[0m )\n\u001b[0;32m-> 1830\u001b[0m feature_info \u001b[39m=\u001b[39m from_cstr_to_pystr(sarr, length)\n\u001b[1;32m   1831\u001b[0m \u001b[39mreturn\u001b[39;00m feature_info \u001b[39mif\u001b[39;00m feature_info \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:102\u001b[0m, in \u001b[0;36mfrom_cstr_to_pystr\u001b[0;34m(data, length)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length\u001b[39m.\u001b[39mvalue):\n\u001b[1;32m    101\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         res\u001b[39m.\u001b[39;49mappend(\u001b[39mstr\u001b[39;49m(cast(\u001b[39mbytes\u001b[39;49m, data[i])\u001b[39m.\u001b[39;49mdecode(\u001b[39m'\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m    103\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         res\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(cast(\u001b[39mbytes\u001b[39m, data[i])\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Optuna Objective Function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 150, step=10),\n",
    "        'alpha': trial.suggest_float('alpha', 0, 1),\n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "\n",
    "    model_xgb = MultiOutputClassifier(xgb.XGBClassifier(**params))\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels for test data\n",
    "    predicted_labels = model_xgb.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model's accuracy (note: this will give average accuracy over all labels)\n",
    "    accuracy = (predicted_labels == y_test).mean().mean()  # First mean over instances, second over labels\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Optuna Optimization\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params_xgb = study.best_params\n",
    "best_score_xgb = study.best_value\n",
    "\n",
    "print('Best Hyperparameters:', best_params_xgb)\n",
    "print('Best Accuracy:', best_score_xgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb={'learning_rate': 0.3093742069137974, 'max_depth': 9, 'subsample': 0.8492629160126342, 'colsample_bytree': 0.9265396146576996, 'n_estimators': 150, 'alpha': 0.29594042034438417}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944513953108843"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = MultiOutputClassifier(xgb.XGBClassifier(**best_params_xgb))\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for test data\n",
    "predicted_labels = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy (note: this will give average accuracy over all labels)\n",
    "accuracy = (predicted_labels == y_test).mean().mean()  # First mean over instances, second over labels\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ON the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/Users/leo/Desktop/Day3/dataset_day3/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new=df_test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize text\n",
    "X_test_new = X_test_new.apply(simple_preprocess)\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# # Word2Vec parameters\n",
    "# vector_size = 50  # Change based on your computational capabilities\n",
    "# window = 5\n",
    "# min_count = 2\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# model = Word2Vec(sentences=X_test_new, vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
    "\n",
    "# # Save model for future use if needed\n",
    "# model.save(\"word2vec_model.model\")\n",
    "# import numpy as np\n",
    "\n",
    "# def document_vector(word2vec_model, doc):\n",
    "#     # remove out-of-vocabulary words\n",
    "#     doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "#     if len(doc) == 0:\n",
    "#         return np.zeros(word2vec_model.vector_size)\n",
    "#     else:\n",
    "#         return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "X_test_new = X_test_new.apply(lambda x: document_vector(model, x))\n",
    "X_test_new = pd.DataFrame(X_test_new.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for test data\n",
    "predicted_labels = model_xgb.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(predicted_labels)\n",
    "# Export the DataFrame to a CSV file\n",
    "df_output.to_csv('output3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2486 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  83  84  85  86  87  88  89  \\\n",
       "0      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "2481   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2482   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2483   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2484   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2485   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "      90  91  92  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   0  \n",
       "3      0   0   0  \n",
       "4      0   0   0  \n",
       "...   ..  ..  ..  \n",
       "2481   0   0   0  \n",
       "2482   0   0   0  \n",
       "2483   0   0   0  \n",
       "2484   0   0   0  \n",
       "2485   0   0   0  \n",
       "\n",
       "[2486 rows x 93 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelPowerset(classifier=RandomForestClassifier(), require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelPowerset</label><div class=\"sk-toggleable__content\"><pre>LabelPowerset(classifier=RandomForestClassifier(), require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelPowerset(classifier=RandomForestClassifier(), require_dense=[True, True])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # using Label Powerset\n",
    "# from skmultilearn.problem_transform import LabelPowerset\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # initialize label powerset multi-label classifier\n",
    "# classifier = LabelPowerset(RandomForestClassifier())\n",
    "# # train\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.16020236087689713\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # predict\n",
    "# predictions = classifier.predict(X_test)\n",
    "# # accuracy\n",
    "# print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "# print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
